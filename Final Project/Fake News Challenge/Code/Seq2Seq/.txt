0
Training loss:  4.19143439595e+18
Dev error rate:  0.5
0
[[  1.   0.   1.   5.]
 [  0.   0.   0.   1.]
 [  0.   0.   0.   0.]
 [  3.   1.   6.  16.]]
1
Training loss:  1.39275612274e+33
Dev error rate:  0.676470588235
1
[[ 0.  0.  0.  2.]
 [ 0.  0.  0.  2.]
 [ 2.  1.  2.  9.]
 [ 2.  0.  5.  9.]]
2
Training loss:  1.29916859823e+30
Dev error rate:  0.617647058824
2
[[  0.   0.   0.   3.]
 [  0.   0.   0.   2.]
 [  1.   0.   1.   5.]
 [  3.   1.   6.  12.]]
3
Training loss:  5.58250226169e+26
Dev error rate:  0.382352941176
3
[[  0.   0.   0.   0.]
 [  0.   0.   0.   1.]
 [  0.   0.   0.   0.]
 [  4.   1.   7.  21.]]
4
Training loss:  4.34295121447e+31
Dev error rate:  0.382352941176
4
[[  0.   0.   0.   0.]
 [  0.   0.   0.   1.]
 [  2.   1.   0.   0.]
 [  2.   0.   7.  21.]]
5
Training loss:  2.35122385487e+27
Dev error rate:  0.558823529412
5
[[  0.   0.   0.   1.]
 [  0.   1.   0.   3.]
 [  2.   0.   1.   5.]
 [  2.   0.   6.  13.]]
6
Training loss:  1.21492341807e+25
Dev error rate:  0.470588235294
6
[[  0.   0.   2.   1.]
 [  0.   1.   0.   2.]
 [  1.   0.   0.   2.]
 [  3.   0.   5.  17.]]
7
Training loss:  2.98918199412e+25
Dev error rate:  0.529411764706
7
[[  1.   0.   1.   4.]
 [  0.   0.   0.   0.]
 [  1.   1.   2.   5.]
 [  2.   0.   4.  13.]]
8
Training loss:  1.54517506899e+25
Dev error rate:  0.5
8
[[  1.   0.   0.   1.]
 [  0.   0.   0.   0.]
 [  1.   1.   2.   7.]
 [  2.   0.   5.  14.]]
9
Training loss:  2.18275227436e+22
Dev error rate:  0.411764705882
9
[[  0.   0.   0.   1.]
 [  0.   0.   1.   0.]
 [  1.   0.   1.   2.]
 [  3.   1.   5.  19.]]
0
Training loss:  0.872389098008
Dev error rate:  0.352941176471
0
[[  0.   0.   0.   0.]
 [  0.   0.   0.   0.]
 [  0.   0.   0.   0.]
 [  4.   1.   7.  22.]]
1
Training loss:  0.801435281833
Dev error rate:  0.352941176471
1
[[  0.   0.   0.   0.]
 [  0.   0.   0.   0.]
 [  0.   0.   0.   0.]
 [  4.   1.   7.  22.]]
